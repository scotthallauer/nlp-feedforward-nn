NGRAM_SIZE = 6
EMBEDDING_DIM = 10
BATCH_SIZE = 256
INITIAL_LEARNING_RATE = 0.1

Start Training
| epoch 1 | 200/ 2561 batches | lr 0.1000 | ms/batch 4.49 | loss 10.63 | ppl 42571.53
| epoch 1 | 400/ 2561 batches | lr 0.1000 | ms/batch 4.38 | loss 10.29 | ppl 29707.19
| epoch 1 | 600/ 2561 batches | lr 0.1000 | ms/batch 4.38 | loss 10.12 | ppl 25224.79
| epoch 1 | 800/ 2561 batches | lr 0.1000 | ms/batch 4.42 | loss 10.00 | ppl 22306.51
| epoch 1 | 1000/ 2561 batches | lr 0.1000 | ms/batch 4.40 | loss 9.88 | ppl 19774.58
| epoch 1 | 1200/ 2561 batches | lr 0.1000 | ms/batch 4.42 | loss 9.74 | ppl 17272.89
| epoch 1 | 1400/ 2561 batches | lr 0.1000 | ms/batch 4.42 | loss 9.65 | ppl 15750.67
| epoch 1 | 1600/ 2561 batches | lr 0.1000 | ms/batch 4.39 | loss 9.57 | ppl 14570.86
| epoch 1 | 1800/ 2561 batches | lr 0.1000 | ms/batch 4.41 | loss 9.50 | ppl 13496.88
| epoch 1 | 2000/ 2561 batches | lr 0.1000 | ms/batch 4.39 | loss 9.43 | ppl 12686.64
| epoch 1 | 2200/ 2561 batches | lr 0.1000 | ms/batch 4.39 | loss 9.36 | ppl 11779.74
| epoch 1 | 2400/ 2561 batches | lr 0.1000 | ms/batch 4.39 | loss 9.32 | ppl 11315.55
-------------------------------------------------------------------
| end of epoch 1 | time: 51.03s | valid loss 8.46 | valid ppl 4806.90
-------------------------------------------------------------------
Start Training
| epoch 2 | 200/ 2561 batches | lr 0.0900 | ms/batch 4.42 | loss 9.23 | ppl 10353.78
| epoch 2 | 400/ 2561 batches | lr 0.0900 | ms/batch 4.39 | loss 9.21 | ppl 10204.49
| epoch 2 | 600/ 2561 batches | lr 0.0900 | ms/batch 4.41 | loss 9.19 | ppl 9995.43
| epoch 2 | 800/ 2561 batches | lr 0.0900 | ms/batch 4.42 | loss 9.17 | ppl 9725.61
| epoch 2 | 1000/ 2561 batches | lr 0.0900 | ms/batch 4.43 | loss 9.12 | ppl 9328.97
| epoch 2 | 1200/ 2561 batches | lr 0.0900 | ms/batch 4.41 | loss 9.11 | ppl 9173.74
| epoch 2 | 1400/ 2561 batches | lr 0.0900 | ms/batch 4.41 | loss 9.08 | ppl 8957.36
| epoch 2 | 1600/ 2561 batches | lr 0.0900 | ms/batch 4.40 | loss 9.06 | ppl 8758.86
| epoch 2 | 1800/ 2561 batches | lr 0.0900 | ms/batch 4.42 | loss 9.05 | ppl 8684.27
| epoch 2 | 2000/ 2561 batches | lr 0.0900 | ms/batch 4.44 | loss 9.07 | ppl 8861.56
| epoch 2 | 2200/ 2561 batches | lr 0.0900 | ms/batch 4.39 | loss 9.05 | ppl 8731.72
| epoch 2 | 2400/ 2561 batches | lr 0.0900 | ms/batch 4.42 | loss 9.04 | ppl 8581.02
-------------------------------------------------------------------
| end of epoch 2 | time: 51.23s | valid loss 8.21 | valid ppl 3754.48
-------------------------------------------------------------------
Start Training
| epoch 3 | 200/ 2561 batches | lr 0.0810 | ms/batch 4.45 | loss 9.00 | ppl 8204.72
| epoch 3 | 400/ 2561 batches | lr 0.0810 | ms/batch 4.49 | loss 8.97 | ppl 7974.87
| epoch 3 | 600/ 2561 batches | lr 0.0810 | ms/batch 4.42 | loss 8.99 | ppl 8113.39
| epoch 3 | 800/ 2561 batches | lr 0.0810 | ms/batch 4.42 | loss 8.98 | ppl 8070.69
| epoch 3 | 1000/ 2561 batches | lr 0.0810 | ms/batch 4.41 | loss 9.01 | ppl 8272.35
| epoch 3 | 1200/ 2561 batches | lr 0.0810 | ms/batch 4.43 | loss 8.95 | ppl 7854.44
| epoch 3 | 1400/ 2561 batches | lr 0.0810 | ms/batch 4.41 | loss 8.97 | ppl 7993.40
| epoch 3 | 1600/ 2561 batches | lr 0.0810 | ms/batch 4.40 | loss 8.98 | ppl 8083.18
| epoch 3 | 1800/ 2561 batches | lr 0.0810 | ms/batch 4.47 | loss 8.96 | ppl 7883.65
| epoch 3 | 2000/ 2561 batches | lr 0.0810 | ms/batch 4.39 | loss 8.95 | ppl 7786.27
| epoch 3 | 2200/ 2561 batches | lr 0.0810 | ms/batch 4.43 | loss 8.94 | ppl 7697.50
| epoch 3 | 2400/ 2561 batches | lr 0.0810 | ms/batch 4.40 | loss 8.95 | ppl 7803.20
-------------------------------------------------------------------
| end of epoch 3 | time: 51.10s | valid loss 8.14 | valid ppl 3520.88
-------------------------------------------------------------------
Start Training
| epoch 4 | 200/ 2561 batches | lr 0.0729 | ms/batch 4.42 | loss 8.92 | ppl 7601.11
| epoch 4 | 400/ 2561 batches | lr 0.0729 | ms/batch 4.42 | loss 8.93 | ppl 7647.23
| epoch 4 | 600/ 2561 batches | lr 0.0729 | ms/batch 4.39 | loss 8.90 | ppl 7424.64
| epoch 4 | 800/ 2561 batches | lr 0.0729 | ms/batch 4.42 | loss 8.94 | ppl 7713.61
| epoch 4 | 1000/ 2561 batches | lr 0.0729 | ms/batch 4.43 | loss 8.90 | ppl 7429.43
| epoch 4 | 1200/ 2561 batches | lr 0.0729 | ms/batch 4.43 | loss 8.90 | ppl 7415.32
| epoch 4 | 1400/ 2561 batches | lr 0.0729 | ms/batch 4.44 | loss 8.92 | ppl 7632.54
| epoch 4 | 1600/ 2561 batches | lr 0.0729 | ms/batch 4.43 | loss 8.91 | ppl 7497.31
| epoch 4 | 1800/ 2561 batches | lr 0.0729 | ms/batch 4.45 | loss 8.90 | ppl 7404.45
| epoch 4 | 2000/ 2561 batches | lr 0.0729 | ms/batch 4.46 | loss 8.89 | ppl 7340.07
| epoch 4 | 2200/ 2561 batches | lr 0.0729 | ms/batch 4.43 | loss 8.89 | ppl 7408.31
| epoch 4 | 2400/ 2561 batches | lr 0.0729 | ms/batch 4.45 | loss 8.86 | ppl 7175.11
-------------------------------------------------------------------
| end of epoch 4 | time: 51.31s | valid loss 8.13 | valid ppl 3466.09
-------------------------------------------------------------------
Start Training
| epoch 5 | 200/ 2561 batches | lr 0.0656 | ms/batch 4.41 | loss 8.89 | ppl 7365.78
| epoch 5 | 400/ 2561 batches | lr 0.0656 | ms/batch 4.43 | loss 8.85 | ppl 7114.85
| epoch 5 | 600/ 2561 batches | lr 0.0656 | ms/batch 4.44 | loss 8.88 | ppl 7317.45
| epoch 5 | 800/ 2561 batches | lr 0.0656 | ms/batch 4.43 | loss 8.85 | ppl 7083.97
| epoch 5 | 1000/ 2561 batches | lr 0.0656 | ms/batch 4.40 | loss 8.85 | ppl 7085.77
| epoch 5 | 1200/ 2561 batches | lr 0.0656 | ms/batch 4.46 | loss 8.87 | ppl 7233.97
| epoch 5 | 1400/ 2561 batches | lr 0.0656 | ms/batch 4.43 | loss 8.85 | ppl 7097.15
| epoch 5 | 1600/ 2561 batches | lr 0.0656 | ms/batch 4.40 | loss 8.86 | ppl 7113.77
| epoch 5 | 1800/ 2561 batches | lr 0.0656 | ms/batch 4.39 | loss 8.86 | ppl 7157.99
| epoch 5 | 2000/ 2561 batches | lr 0.0656 | ms/batch 4.42 | loss 8.86 | ppl 7124.02
| epoch 5 | 2200/ 2561 batches | lr 0.0656 | ms/batch 4.43 | loss 8.87 | ppl 7201.23
| epoch 5 | 2400/ 2561 batches | lr 0.0656 | ms/batch 4.41 | loss 8.86 | ppl 7178.01
-------------------------------------------------------------------
| end of epoch 5 | time: 50.84s | valid loss 8.09 | valid ppl 3336.84
-------------------------------------------------------------------
=========================================================================================
| End of training | test loss 8.10 | test ppl 3345.06
=========================================================================================
NGRAM_SIZE = 6
EMBEDDING_DIM = 10
BATCH_SIZE = 400
INITIAL_LEARNING_RATE = 0.1

Start Training
| epoch 1 | 200/ 1639 batches | lr 0.1000 | ms/batch 6.60 | loss 10.63 | ppl 42314.11
| epoch 1 | 400/ 1639 batches | lr 0.1000 | ms/batch 6.56 | loss 10.29 | ppl 29687.15
| epoch 1 | 600/ 1639 batches | lr 0.1000 | ms/batch 6.49 | loss 10.15 | ppl 25693.72
| epoch 1 | 800/ 1639 batches | lr 0.1000 | ms/batch 6.55 | loss 10.00 | ppl 22254.88
| epoch 1 | 1000/ 1639 batches | lr 0.1000 | ms/batch 6.59 | loss 9.89 | ppl 19873.94
| epoch 1 | 1200/ 1639 batches | lr 0.1000 | ms/batch 6.53 | loss 9.77 | ppl 17698.43
| epoch 1 | 1400/ 1639 batches | lr 0.1000 | ms/batch 6.59 | loss 9.65 | ppl 15711.08
| epoch 1 | 1600/ 1639 batches | lr 0.1000 | ms/batch 6.56 | loss 9.58 | ppl 14686.21
-------------------------------------------------------------------
| end of epoch 1 | time: 51.69s | valid loss 8.73 | valid ppl 6279.13
-------------------------------------------------------------------
Start Training
| epoch 2 | 200/ 1639 batches | lr 0.0900 | ms/batch 6.55 | loss 9.48 | ppl 13243.30
| epoch 2 | 400/ 1639 batches | lr 0.0900 | ms/batch 6.54 | loss 9.40 | ppl 12244.61
| epoch 2 | 600/ 1639 batches | lr 0.0900 | ms/batch 6.60 | loss 9.38 | ppl 11960.82
| epoch 2 | 800/ 1639 batches | lr 0.0900 | ms/batch 6.48 | loss 9.32 | ppl 11244.83
| epoch 2 | 1000/ 1639 batches | lr 0.0900 | ms/batch 6.59 | loss 9.29 | ppl 10918.83
| epoch 2 | 1200/ 1639 batches | lr 0.0900 | ms/batch 6.56 | loss 9.24 | ppl 10420.94
| epoch 2 | 1400/ 1639 batches | lr 0.0900 | ms/batch 6.51 | loss 9.23 | ppl 10259.22
| epoch 2 | 1600/ 1639 batches | lr 0.0900 | ms/batch 6.52 | loss 9.19 | ppl 9860.17
-------------------------------------------------------------------
| end of epoch 2 | time: 51.59s | valid loss 8.35 | valid ppl 4286.88
-------------------------------------------------------------------
Start Training
| epoch 3 | 200/ 1639 batches | lr 0.0810 | ms/batch 6.56 | loss 9.15 | ppl 9564.13
| epoch 3 | 400/ 1639 batches | lr 0.0810 | ms/batch 6.50 | loss 9.13 | ppl 9345.77
| epoch 3 | 600/ 1639 batches | lr 0.0810 | ms/batch 6.56 | loss 9.11 | ppl 9167.99
| epoch 3 | 800/ 1639 batches | lr 0.0810 | ms/batch 6.63 | loss 9.10 | ppl 9025.64
| epoch 3 | 1000/ 1639 batches | lr 0.0810 | ms/batch 6.63 | loss 9.08 | ppl 8869.69
| epoch 3 | 1200/ 1639 batches | lr 0.0810 | ms/batch 6.65 | loss 9.06 | ppl 8732.23
| epoch 3 | 1400/ 1639 batches | lr 0.0810 | ms/batch 6.70 | loss 9.05 | ppl 8642.94
| epoch 3 | 1600/ 1639 batches | lr 0.0810 | ms/batch 6.66 | loss 9.03 | ppl 8469.71
-------------------------------------------------------------------
| end of epoch 3 | time: 52.09s | valid loss 8.23 | valid ppl 3787.83
-------------------------------------------------------------------
Start Training
| epoch 4 | 200/ 1639 batches | lr 0.0729 | ms/batch 6.60 | loss 9.02 | ppl 8333.49
| epoch 4 | 400/ 1639 batches | lr 0.0729 | ms/batch 6.68 | loss 9.00 | ppl 8228.81
| epoch 4 | 600/ 1639 batches | lr 0.0729 | ms/batch 6.66 | loss 9.01 | ppl 8262.46
| epoch 4 | 800/ 1639 batches | lr 0.0729 | ms/batch 6.66 | loss 9.02 | ppl 8323.57
| epoch 4 | 1000/ 1639 batches | lr 0.0729 | ms/batch 6.65 | loss 8.98 | ppl 8000.85
| epoch 4 | 1200/ 1639 batches | lr 0.0729 | ms/batch 6.65 | loss 8.99 | ppl 8084.15
| epoch 4 | 1400/ 1639 batches | lr 0.0729 | ms/batch 6.65 | loss 9.00 | ppl 8158.88
| epoch 4 | 1600/ 1639 batches | lr 0.0729 | ms/batch 6.65 | loss 8.96 | ppl 7861.40
-------------------------------------------------------------------
| end of epoch 4 | time: 52.34s | valid loss 8.19 | valid ppl 3674.43
-------------------------------------------------------------------
Start Training
| epoch 5 | 200/ 1639 batches | lr 0.0656 | ms/batch 6.68 | loss 8.95 | ppl 7769.70
| epoch 5 | 400/ 1639 batches | lr 0.0656 | ms/batch 6.63 | loss 8.95 | ppl 7756.08
| epoch 5 | 600/ 1639 batches | lr 0.0656 | ms/batch 6.62 | loss 8.95 | ppl 7794.59
| epoch 5 | 800/ 1639 batches | lr 0.0656 | ms/batch 6.60 | loss 8.94 | ppl 7687.42
| epoch 5 | 1000/ 1639 batches | lr 0.0656 | ms/batch 6.59 | loss 8.93 | ppl 7645.61
| epoch 5 | 1200/ 1639 batches | lr 0.0656 | ms/batch 6.66 | loss 8.95 | ppl 7758.62
| epoch 5 | 1400/ 1639 batches | lr 0.0656 | ms/batch 6.65 | loss 8.94 | ppl 7672.31
| epoch 5 | 1600/ 1639 batches | lr 0.0656 | ms/batch 6.67 | loss 8.94 | ppl 7676.20
-------------------------------------------------------------------
| end of epoch 5 | time: 52.25s | valid loss 8.14 | valid ppl 3468.06
-------------------------------------------------------------------
=========================================================================================
| End of training | test loss 8.14 | test ppl 3488.65
=========================================================================================
NGRAM_SIZE = 6
EMBEDDING_DIM = 100
BATCH_SIZE = 400
INITIAL_LEARNING_RATE = 0.1

Start Training
| epoch 1 | 200/ 1639 batches | lr 0.1000 | ms/batch 7.50 | loss 10.61 | ppl 41617.36
| epoch 1 | 400/ 1639 batches | lr 0.1000 | ms/batch 6.37 | loss 10.26 | ppl 28773.03
| epoch 1 | 600/ 1639 batches | lr 0.1000 | ms/batch 6.44 | loss 10.09 | ppl 24383.72
| epoch 1 | 800/ 1639 batches | lr 0.1000 | ms/batch 6.40 | loss 9.94 | ppl 20837.66
| epoch 1 | 1000/ 1639 batches | lr 0.1000 | ms/batch 6.45 | loss 9.82 | ppl 18557.17
| epoch 1 | 1200/ 1639 batches | lr 0.1000 | ms/batch 6.39 | loss 9.70 | ppl 16466.23
| epoch 1 | 1400/ 1639 batches | lr 0.1000 | ms/batch 6.38 | loss 9.58 | ppl 14672.87
| epoch 1 | 1600/ 1639 batches | lr 0.1000 | ms/batch 6.38 | loss 9.50 | ppl 13435.07
-------------------------------------------------------------------
| end of epoch 1 | time: 51.85s | valid loss 8.69 | valid ppl 6034.75
-------------------------------------------------------------------
Start Training
| epoch 2 | 200/ 1639 batches | lr 0.0900 | ms/batch 6.41 | loss 9.38 | ppl 12034.79
| epoch 2 | 400/ 1639 batches | lr 0.0900 | ms/batch 6.46 | loss 9.32 | ppl 11284.39
| epoch 2 | 600/ 1639 batches | lr 0.0900 | ms/batch 6.42 | loss 9.27 | ppl 10755.03
| epoch 2 | 800/ 1639 batches | lr 0.0900 | ms/batch 6.41 | loss 9.23 | ppl 10360.12
| epoch 2 | 1000/ 1639 batches | lr 0.0900 | ms/batch 6.43 | loss 9.18 | ppl 9787.80
| epoch 2 | 1200/ 1639 batches | lr 0.0900 | ms/batch 6.44 | loss 9.15 | ppl 9499.40
| epoch 2 | 1400/ 1639 batches | lr 0.0900 | ms/batch 6.42 | loss 9.14 | ppl 9372.77
| epoch 2 | 1600/ 1639 batches | lr 0.0900 | ms/batch 6.43 | loss 9.08 | ppl 8913.57
-------------------------------------------------------------------
| end of epoch 2 | time: 51.56s | valid loss 8.37 | valid ppl 4348.63
-------------------------------------------------------------------
Start Training
| epoch 3 | 200/ 1639 batches | lr 0.0810 | ms/batch 6.43 | loss 9.03 | ppl 8428.16
| epoch 3 | 400/ 1639 batches | lr 0.0810 | ms/batch 6.46 | loss 9.01 | ppl 8286.68
| epoch 3 | 600/ 1639 batches | lr 0.0810 | ms/batch 6.46 | loss 8.99 | ppl 8072.16
| epoch 3 | 800/ 1639 batches | lr 0.0810 | ms/batch 6.53 | loss 8.98 | ppl 8021.30
| epoch 3 | 1000/ 1639 batches | lr 0.0810 | ms/batch 6.45 | loss 8.95 | ppl 7819.76
| epoch 3 | 1200/ 1639 batches | lr 0.0810 | ms/batch 6.47 | loss 8.96 | ppl 7839.89
| epoch 3 | 1400/ 1639 batches | lr 0.0810 | ms/batch 6.48 | loss 8.94 | ppl 7750.00
| epoch 3 | 1600/ 1639 batches | lr 0.0810 | ms/batch 6.45 | loss 8.92 | ppl 7581.28
-------------------------------------------------------------------
| end of epoch 3 | time: 51.98s | valid loss 8.21 | valid ppl 3758.20
-------------------------------------------------------------------
Start Training
| epoch 4 | 200/ 1639 batches | lr 0.0729 | ms/batch 6.45 | loss 8.88 | ppl 7242.38
| epoch 4 | 400/ 1639 batches | lr 0.0729 | ms/batch 6.44 | loss 8.86 | ppl 7142.44
| epoch 4 | 600/ 1639 batches | lr 0.0729 | ms/batch 6.44 | loss 8.87 | ppl 7176.03
| epoch 4 | 800/ 1639 batches | lr 0.0729 | ms/batch 6.49 | loss 8.85 | ppl 7056.91
| epoch 4 | 1000/ 1639 batches | lr 0.0729 | ms/batch 6.48 | loss 8.84 | ppl 6960.31
| epoch 4 | 1200/ 1639 batches | lr 0.0729 | ms/batch 6.44 | loss 8.85 | ppl 7015.36
| epoch 4 | 1400/ 1639 batches | lr 0.0729 | ms/batch 6.45 | loss 8.82 | ppl 6891.35
| epoch 4 | 1600/ 1639 batches | lr 0.0729 | ms/batch 6.43 | loss 8.82 | ppl 6837.41
-------------------------------------------------------------------
| end of epoch 4 | time: 52.13s | valid loss 8.16 | valid ppl 3533.46
-------------------------------------------------------------------
Start Training
| epoch 5 | 200/ 1639 batches | lr 0.0656 | ms/batch 6.43 | loss 8.78 | ppl 6535.26
| epoch 5 | 400/ 1639 batches | lr 0.0656 | ms/batch 6.43 | loss 8.75 | ppl 6409.13
| epoch 5 | 600/ 1639 batches | lr 0.0656 | ms/batch 6.48 | loss 8.81 | ppl 6745.13
| epoch 5 | 800/ 1639 batches | lr 0.0656 | ms/batch 6.47 | loss 8.77 | ppl 6528.02
| epoch 5 | 1000/ 1639 batches | lr 0.0656 | ms/batch 6.44 | loss 8.77 | ppl 6504.99
| epoch 5 | 1200/ 1639 batches | lr 0.0656 | ms/batch 6.45 | loss 8.76 | ppl 6463.94
| epoch 5 | 1400/ 1639 batches | lr 0.0656 | ms/batch 6.42 | loss 8.74 | ppl 6345.62
| epoch 5 | 1600/ 1639 batches | lr 0.0656 | ms/batch 6.44 | loss 8.75 | ppl 6378.00
-------------------------------------------------------------------
| end of epoch 5 | time: 51.68s | valid loss 8.12 | valid ppl 3402.40
-------------------------------------------------------------------
=========================================================================================
| End of training | test loss 8.11 | test ppl 3379.12
=========================================================================================

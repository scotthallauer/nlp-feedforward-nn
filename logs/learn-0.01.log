NGRAM_SIZE = 6
EMBEDDING_DIM = 10
BATCH_SIZE = 400
INITIAL_LEARNING_RATE = 0.01

Start Training
| epoch 1 | 200/ 1639 batches | lr 0.0100 | ms/batch 6.56 | loss 11.03 | ppl 61723.06
| epoch 1 | 400/ 1639 batches | lr 0.0100 | ms/batch 6.40 | loss 10.92 | ppl 55218.02
| epoch 1 | 600/ 1639 batches | lr 0.0100 | ms/batch 6.41 | loss 10.79 | ppl 48773.76
| epoch 1 | 800/ 1639 batches | lr 0.0100 | ms/batch 6.44 | loss 10.66 | ppl 42905.49
| epoch 1 | 1000/ 1639 batches | lr 0.0100 | ms/batch 6.42 | loss 10.58 | ppl 39496.33
| epoch 1 | 1200/ 1639 batches | lr 0.0100 | ms/batch 6.41 | loss 10.52 | ppl 37042.14
| epoch 1 | 1400/ 1639 batches | lr 0.0100 | ms/batch 6.38 | loss 10.48 | ppl 35892.33
| epoch 1 | 1600/ 1639 batches | lr 0.0100 | ms/batch 6.39 | loss 10.48 | ppl 35873.21
-------------------------------------------------------------------
| end of epoch 1 | time: 51.67s | valid loss 9.77 | valid ppl 17792.22
-------------------------------------------------------------------
Start Training
| epoch 2 | 200/ 1639 batches | lr 0.0090 | ms/batch 6.39 | loss 10.43 | ppl 33917.18
| epoch 2 | 400/ 1639 batches | lr 0.0090 | ms/batch 6.41 | loss 10.40 | ppl 32911.51
| epoch 2 | 600/ 1639 batches | lr 0.0090 | ms/batch 6.41 | loss 10.40 | ppl 33150.92
| epoch 2 | 800/ 1639 batches | lr 0.0090 | ms/batch 6.38 | loss 10.37 | ppl 32107.09
| epoch 2 | 1000/ 1639 batches | lr 0.0090 | ms/batch 6.36 | loss 10.36 | ppl 31765.64
| epoch 2 | 1200/ 1639 batches | lr 0.0090 | ms/batch 6.39 | loss 10.34 | ppl 31285.80
| epoch 2 | 1400/ 1639 batches | lr 0.0090 | ms/batch 6.40 | loss 10.32 | ppl 30635.02
| epoch 2 | 1600/ 1639 batches | lr 0.0090 | ms/batch 6.43 | loss 10.29 | ppl 29654.31
-------------------------------------------------------------------
| end of epoch 2 | time: 51.11s | valid loss 9.58 | valid ppl 14562.61
-------------------------------------------------------------------
Start Training
| epoch 3 | 200/ 1639 batches | lr 0.0081 | ms/batch 6.40 | loss 10.29 | ppl 29440.57
| epoch 3 | 400/ 1639 batches | lr 0.0081 | ms/batch 6.38 | loss 10.27 | ppl 28958.48
| epoch 3 | 600/ 1639 batches | lr 0.0081 | ms/batch 6.42 | loss 10.25 | ppl 28441.48
| epoch 3 | 800/ 1639 batches | lr 0.0081 | ms/batch 6.41 | loss 10.23 | ppl 27876.62
| epoch 3 | 1000/ 1639 batches | lr 0.0081 | ms/batch 6.40 | loss 10.22 | ppl 27615.35
| epoch 3 | 1200/ 1639 batches | lr 0.0081 | ms/batch 6.40 | loss 10.21 | ppl 27397.10
| epoch 3 | 1400/ 1639 batches | lr 0.0081 | ms/batch 6.39 | loss 10.20 | ppl 27138.77
| epoch 3 | 1600/ 1639 batches | lr 0.0081 | ms/batch 6.39 | loss 10.18 | ppl 26470.93
-------------------------------------------------------------------
| end of epoch 3 | time: 51.34s | valid loss 9.46 | valid ppl 13033.57
-------------------------------------------------------------------
Start Training
| epoch 4 | 200/ 1639 batches | lr 0.0073 | ms/batch 6.38 | loss 10.19 | ppl 26703.37
| epoch 4 | 400/ 1639 batches | lr 0.0073 | ms/batch 6.37 | loss 10.17 | ppl 26350.77
| epoch 4 | 600/ 1639 batches | lr 0.0073 | ms/batch 6.40 | loss 10.15 | ppl 25691.43
| epoch 4 | 800/ 1639 batches | lr 0.0073 | ms/batch 6.38 | loss 10.16 | ppl 26099.73
| epoch 4 | 1000/ 1639 batches | lr 0.0073 | ms/batch 6.38 | loss 10.13 | ppl 25202.36
| epoch 4 | 1200/ 1639 batches | lr 0.0073 | ms/batch 6.38 | loss 10.13 | ppl 25196.64
| epoch 4 | 1400/ 1639 batches | lr 0.0073 | ms/batch 6.42 | loss 10.09 | ppl 24374.30
| epoch 4 | 1600/ 1639 batches | lr 0.0073 | ms/batch 6.40 | loss 10.09 | ppl 24206.09
-------------------------------------------------------------------
| end of epoch 4 | time: 50.91s | valid loss 9.36 | valid ppl 11712.28
-------------------------------------------------------------------
Start Training
| epoch 5 | 200/ 1639 batches | lr 0.0066 | ms/batch 6.37 | loss 10.08 | ppl 24054.22
| epoch 5 | 400/ 1639 batches | lr 0.0066 | ms/batch 6.37 | loss 10.08 | ppl 24079.01
| epoch 5 | 600/ 1639 batches | lr 0.0066 | ms/batch 6.40 | loss 10.06 | ppl 23530.27
| epoch 5 | 800/ 1639 batches | lr 0.0066 | ms/batch 6.39 | loss 10.06 | ppl 23488.93
| epoch 5 | 1000/ 1639 batches | lr 0.0066 | ms/batch 6.38 | loss 10.05 | ppl 23420.96
| epoch 5 | 1200/ 1639 batches | lr 0.0066 | ms/batch 6.40 | loss 10.06 | ppl 23524.53
| epoch 5 | 1400/ 1639 batches | lr 0.0066 | ms/batch 6.36 | loss 10.02 | ppl 22775.81
| epoch 5 | 1600/ 1639 batches | lr 0.0066 | ms/batch 6.40 | loss 10.03 | ppl 22952.33
-------------------------------------------------------------------
| end of epoch 5 | time: 50.97s | valid loss 9.28 | valid ppl 10773.26
-------------------------------------------------------------------
=========================================================================================
| End of training | test loss 9.26 | test ppl 10588.50
=========================================================================================